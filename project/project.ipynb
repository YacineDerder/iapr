{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import skimage.morphology\n",
    "import skimage\n",
    "from skimage import measure\n",
    "from skimage import io, filters\n",
    "from skimage.filters import gabor_kernel\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "import imutils\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from save_evaluation_files import export_solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Project\n",
    "\n",
    "\n",
    "**Group ID:** 14\n",
    "\n",
    "**Author 1 (sciper):** David Rüegg (218512)  \n",
    "**Author 2 (sciper):** Yacine Derder (301994)   \n",
    "**Author 3 (sciper):** Elsa Pariat (301964)   \n",
    "\n",
    "**Release date:** 27.04.2023\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The assignments are designed to teach practical implementation of the topics presented during class as well as preparation for the final project, which is a practical project which ties together the topics of the course. \n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook !** rerun the notebook from scratch `Kernel` > `Restart & Run All`\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Introduction\n",
    "\n",
    "In this project, you will be working on solving tiling puzzles using image analysis and pattern recognition techniques. Tiling puzzles are a classic type of puzzle game that consists of fitting together pieces of a given shape (in this case squared to form a complete image. The goal of this project is to develop an algorithm that can automatically reconstruct tiling puzzles from a single input image. \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data\n",
    "\n",
    "### Input data\n",
    "To achieve your task, you will be given images that look like this:\n",
    "\n",
    "\n",
    "![train_00.png](data_project/project_description/train_00.png)\n",
    "\n",
    "### Example puzzle content\n",
    "Example of input of solved puzzles. \n",
    "Solution 1\n",
    "<img src=\"data_project/project_description/solution_example.png\" width=\"512\"/>\n",
    "Solution 2\n",
    "<img src=\"data_project/project_description/solution_example2.jpg\" width=\"512\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Image layout\n",
    "\n",
    "- The input for the program will be a single image with a size of __2000x2000 pixels__, containing the pieces of the tiling puzzles randomly placed in it. The puzzles sizes vary from __3x3, 3x4, or 4x4__ size. \n",
    "    -__You are guaranteed to always have the exact number of pieces for each puzzle__ \n",
    "        -For each puzzle you always are expected to find exaclty 9,12,16 pieces\n",
    "        -If you find something else, either you are missing pieces, or added incorrect pieces for the puzzle\n",
    "\n",
    "- The puzzle pieces are square-shaped with dimensions of 128x128 pixels (before rotation). \n",
    "\n",
    "- The input image will contain pieces from __two or three (but never four)__ different tiling puzzles, as well as some __extra pieces (outliers)__ that do not belong to either puzzle.\n",
    "\n",
    "\n",
    "## 2. Tasks (Total 20 points) \n",
    "\n",
    "\n",
    "The project aims to:\n",
    "1) Segment the puzzle pieces from the background (recover the pieces of 128x128 pixels)   \\[ __5 points__ \\] \n",
    "\n",
    "2) Extract features of interest from puzzle pieces images \\[ __5 points__ \\]   \n",
    "\n",
    "3) Cluster puzzle pieces to identify which puzzle they belong, and identify outliers.  \\[ __5 points__ \\]   \n",
    "\n",
    "4) Solve tiling puzzle (find the rotations and translations to correctly allocate the puzzle pieces in a 3x3, 3x4 or 4x4 array.) \\[ __5 points__ \\]   \n",
    "\n",
    "##### The images used for the puzzles have self-repeating patterns or textures, which ensures that all puzzle pieces contain more or less the same features regardless of how they were cut. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. Output solution pieces.\n",
    "\n",
    "For each inpute image, the output solution will include N images with solved puzzles, where N is the number of puzzles in the input image. and M images, that are Each of these images will contain the solved solution to one of the N puzzles in the input. \n",
    "\n",
    "\n",
    "-  Example input:  train_05.png\n",
    "\n",
    "- Example solution:\n",
    "        -solution_05_00.png solution_05_01.png solution_05_02.png \n",
    "        -outlier_05_00.png outlier_05_01.png outlier_05_02.png ...\n",
    "\n",
    "- Example input:  train_07.png\n",
    "- Example solution:\n",
    "        -solution_07_00.png solution_07_01.png \n",
    "        -outlier_07_00.png outlier_07_01.png outlier_07_02.png ...\n",
    "\n",
    "\n",
    "__Watch out!__ output resolution should always be like this:  \n",
    "<table ><tr><th >Puzzle pieces <th><th> pixel dimentions <th> <th> pixel dimentions <th> <tr>\n",
    "<tr><td> 3x3 <td><td> 384x384 <td><td> 3(128)x3(128) <td> <tr>\n",
    "<tr><td> 3x4 <td><td> 384x512 <td><td> 3(128)x4(128)<tr>\n",
    "<tr><td> 4x4 <td><td> 512x512 <td><td> 4(128)x4(128)<tr>\n",
    "<tr><td> 1x1 (outlier)<td><td> 128x128 <td><td> (1)128x(1)128 <td><tr><table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Order of the solutions (and rotations) it's not a problem for the grading__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "the output solution will be a final image of resolution (1283)x(1283), with each piece correctly placed in its corresponding location in the 3x3 array. Similarly, if the puzzle consists of 3x4 or 4x4 pieces, the output solution will be an image of resolution (1283)x(1284) or (1284)x(1284)\n",
    "\n",
    "\n",
    "\n",
    "### 1.3 Data folder Structure\n",
    "\n",
    "You can download the data for the project here: [download data](https://drive.google.com/drive/folders/1k3xTH0ZhpqZb3xcZ6wsOSjLzxBNYabg3?usp=share_link)\n",
    "\n",
    "```\n",
    "data_project\n",
    "│\n",
    "└─── project_description\n",
    "│    │    example_input.png      # example input images\n",
    "│    │    example_textures1.png      # example input images\n",
    "│    │    example_textures2.png      # example input images\n",
    "│    └─── ultimate_test.jpg   # If it works on that image, you would probably end up with a good score\n",
    "│\n",
    "└─── train\n",
    "│    │    train_00.png        # Train image 00\n",
    "│    │    ...\n",
    "│    │    train_16.png        # Train image 16\n",
    "│    └─── train_labels.csv    # Ground truth of the train set\n",
    "|    \n",
    "└────train_solution\n",
    "│    │    solution_00_00.png        # Solution puzzle 1 from Train image 00\n",
    "│    │    solution_00_01.png        # Solution puzzle 2 from Train image 00\n",
    "│    │    solution_00_02.png        # Solution Puzzle 3 from Train image 00\n",
    "│    │    outlier_00_00.png         # outlier     from Train image 00\n",
    "│    │    outlier_00_01.png         # outlier     from Train image 00\n",
    "│    │    outlier_00_03.png         # outlier     from Train image 00\n",
    "│    │    ...\n",
    "│    │    solution_15_00.png        # Solution puzzle 1 from Train image 15\n",
    "│    │    solution_15_01.png        # Solution puzzle 2 from Train image 15\n",
    "│    │    outlier_15_00.png         # outlier     from Train image 15\n",
    "│    └─── outlier_15_01.png         # outlier     from Train image 15\n",
    "│\n",
    "└─── test\n",
    "     │    test_00.png         # Test image 00 (day of the exam only)\n",
    "     │    ...\n",
    "     └─── test_xx.png             # Test image xx (day of the exam only)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "**Before the exam**\n",
    "   - Create a zipped folder named **groupid_xx.zip** that you upload on moodle (xx being your group number).\n",
    "   - Include a **runnable** code (Jupyter Notebook and external files) and your presentation in the zip folder.\n",
    "   \n",
    "**The day of the exam**\n",
    "   - You will be given a **new folder** (test folder) with few images, but **no ground truth** (no solutions).\n",
    "   - We will ask you to run your pipeline in **real time** and to send us your prediction of the task you obtain with the provided function **save_results**. \n",
    "   - On our side, we will compute the performance of your classification algorithm. \n",
    "   - To evaluate your method, we will use the **evaluate_solution** function presented below. To understand how the provided functions work, please read the documentation of the functions in **utils.py**.\n",
    "   - **Please make sure your function returns the proper data format to avoid points penalty on the day of the exam**. \n",
    "---\n",
    "\n",
    "\n",
    "## 4. Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_input_image(image_index ,  folder =\"train2\" , path = \"data_project\"):\n",
    "    \n",
    "    filename = \"train_{}.png\".format(str(image_index).zfill(2))\n",
    "    path_solution = os.path.join(path,folder , filename )\n",
    "    \n",
    "    im= Image.open(os.path.join(path,folder,filename)).convert('RGB')\n",
    "    im = np.array(im)\n",
    "    return im\n",
    "\n",
    "def save_solution_puzzles(image_index , solved_puzzles, outliers  , folder =\"train2\" , path = \"data_project\"  ,group_id = 0):\n",
    "    \n",
    "    path_solution = os.path.join(path,folder + \"_solution_{}\".format(str(group_id).zfill(2)))\n",
    "    if not  os.path.isdir(path_solution):\n",
    "        os.mkdir(path_solution)\n",
    "\n",
    "    print(path_solution)\n",
    "    for i, puzzle in enumerate(solved_puzzles):\n",
    "        filename =os.path.join(path_solution, \"solution_{}_{}.png\".format(str(image_index).zfill(2), str(i).zfill(2)))\n",
    "        Image.fromarray(puzzle).save(filename)\n",
    "\n",
    "    for i , outlier in enumerate(outliers):\n",
    "        filename =os.path.join(path_solution, \"outlier_{}_{}.png\".format(str(image_index).zfill(2), str(i).zfill(2)))\n",
    "        Image.fromarray(outlier).save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_project\\train2_solution_06\n"
     ]
    }
   ],
   "source": [
    "def solve_and_export_puzzles_image(image_index , folder = \"train2\" , path = \"data_project\"  , group_id = \"00\"):\n",
    "    \"\"\"\n",
    "    Wrapper funciton to load image and save solution\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    image:\n",
    "        index number of the dataset\n",
    "\n",
    "    Returns\n",
    "    \"\"\"\n",
    "\n",
    "      # open the image\n",
    "    image_loaded = load_input_image(image_index , folder = folder , path = path)\n",
    "    #print(image_loaded)\n",
    "    \n",
    "   \n",
    "    ## call functions to solve image_loaded\n",
    "    solved_puzzles = [ (np.random.rand(512,512,3)*255).astype(np.uint8)  for i in range(2) ]\n",
    "    outlier_images = [ (np.random.rand(128,128,3)*255).astype(np.uint8) for i in range(3)]\n",
    "    \n",
    "    save_solution_puzzles (image_index , solved_puzzles , outlier_images , folder = folder ,group_id =group_id)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    return image_loaded , solved_puzzles , outlier_images\n",
    "\n",
    "im, sol , out = solve_and_export_puzzles_image(6 , group_id = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 14\n",
    "# Evaluate all images\n",
    "#games_id = [6,10]  # to evaluate  three images\n",
    "#\n",
    "#for i in games_id :\n",
    "#    \n",
    "#    print(\"solving \" , i)\n",
    "#    # Saving results\n",
    "#    solve_and_export_puzzles_image(6 , group_id = group_id)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "The evaluation metrics will be liberated in the following days. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabor filters\n",
    "\n",
    "$$ gb(x,y) = \\exp \\left( -\\frac{1}{2} \\left( \\frac{x_{\\theta}^2}{\\sigma^2} + \\frac{y_{\\theta}^2}{(\\Gamma\\sigma)^2} \\right) \\right) \\cos \\left( \\frac{2 \\pi}{\\lambda} x_{\\theta} + \\psi \\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_dim = 128\n",
    "\n",
    "def preprocess(img, th_val = 75, trans=\"rgb\", c_k_size=20, o_k_size=5):\n",
    "    if trans[:3] == \"rgb\":\n",
    "        mean_rgb = np.mean(img, axis=(0,1))\n",
    "        pix_dist = np.linalg.norm(img - mean_rgb, axis = 2)\n",
    "    elif trans[:3] == \"hsv\":\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mean_hsv = np.mean(hsv, axis=(0,1))\n",
    "        pix_dist = np.linalg.norm(hsv - mean_hsv, axis = 2)\n",
    "    elif trans[:3] == \"all\":\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        img_all = np.concatenate((img, hsv), axis=2)\n",
    "        mean_all = np.mean(img_all, axis=(0,1))\n",
    "        pix_dist = np.linalg.norm(img_all - mean_all, axis = 2)\n",
    "    else:\n",
    "        raise Exception(\"Invalid Transformation\")\n",
    "    \n",
    "#     print(np.max(pix_dist))\n",
    "#     print(np.min(pix_dist))\n",
    "    \n",
    "    # Threshold\n",
    "    im_prep = np.zeros_like(pix_dist)\n",
    "    if trans[len(trans)-3:len(trans)] == \"esh\":\n",
    "        th_val = filters.threshold_otsu(pix_dist.flatten())\n",
    "#     else:\n",
    "#         th_val = (np.max(pix_dist) + np.min(pix_dist)) / 2\n",
    "    im_prep[pix_dist > th_val] = 255\n",
    "    \n",
    "    # Remove small holes and objects\n",
    "    im_prep = skimage.morphology.remove_small_holes(im_prep.astype(bool), area_threshold=10000).astype(float)*255\n",
    "#     im_prep = skimage.morphology.remove_small_objects(im_prep.astype(bool), min_size=100).astype(float)*255\n",
    "    \n",
    "    # Close then open\n",
    "    kernel = np.ones((c_k_size,c_k_size), np.uint8)\n",
    "    im_prep = cv2.morphologyEx(im_prep, cv2.MORPH_CLOSE, kernel)\n",
    "    #kernel = np.ones((o_k_size,o_k_size), np.uint8)\n",
    "    #im_prep = cv2.morphologyEx(im_prep, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Remove small holes and objects\n",
    "    im_prep = skimage.morphology.remove_small_holes(im_prep.astype(bool), area_threshold=10000).astype(float)*255\n",
    "    \n",
    "    # Remove small holes and objects\n",
    "    kernel = np.ones((o_k_size,o_k_size), np.uint8)\n",
    "    im_prep = cv2.dilate(im_prep,kernel,iterations = 1)\n",
    "    im_prep = skimage.morphology.remove_small_holes(im_prep.astype(bool), area_threshold=10000).astype(np.uint8)*255\n",
    "    im_prep = cv2.erode(im_prep,kernel,iterations = 1)\n",
    "    im_prep = skimage.morphology.remove_small_objects(im_prep.astype(bool), min_size=50).astype(np.uint8)*255\n",
    "    \n",
    "    return im_prep\n",
    "\n",
    "def comb_transf(img):\n",
    "    transforms = [\"rgb\", \"rgb + auto_thresh\", \"hsv\", \"hsv + auto_thresh\", \"all\", \"all + auto_thresh\"]\n",
    "#     transforms = [\"rgb\", \"hsv\", \"all\"]\n",
    "#     transforms = [\"all\"]\n",
    "#     transforms = [\"rgb + auto_thresh\", \"hsv + auto_thresh\", \"all + auto_thresh\"]\n",
    "    \n",
    "    im_prep = np.zeros([img.shape[0], img.shape[1], len(transforms)])\n",
    "    for i in range(len(transforms)):\n",
    "        im_prep[:,:,i] = preprocess(img, trans=transforms[i], th_val = 80)\n",
    "    \n",
    "    im_comb = np.round(np.mean(im_prep, axis=2)/255)*255\n",
    "    \n",
    "    return im_comb\n",
    "\n",
    "def pad_image(image, target_shape):\n",
    "    copy = image.copy()\n",
    "    if image.shape[0] > target_shape[0]:\n",
    "        diff = image.shape[0] - target_shape[0]\n",
    "        copy = image[diff//2:diff//2+target_shape[0], :, :]\n",
    "    if image.shape[1] > target_shape[1]:\n",
    "        diff = image.shape[1] - target_shape[1]\n",
    "        copy = image[:, diff//2:diff//2+target_shape[1], :]\n",
    "    \n",
    "    padded_image = np.zeros(target_shape, dtype=image.dtype)\n",
    "    height_diff = target_shape[0] - copy.shape[0]\n",
    "    width_diff = target_shape[1] - copy.shape[1]\n",
    "    pad_top = height_diff // 2\n",
    "    pad_bottom = height_diff - pad_top\n",
    "    pad_left = width_diff // 2\n",
    "    pad_right = width_diff - pad_left\n",
    "\n",
    "    padded_image[pad_top:pad_top+image.shape[0], pad_left:pad_left+image.shape[1], :] = copy\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def opt_crop(piece_bin, piece_original):\n",
    "    if piece_bin.shape[0] != piece_dim or piece_bin.shape[1] != piece_dim:\n",
    "        i_slide = piece_bin.shape[0]-128\n",
    "        j_slide = piece_bin.shape[1]-128\n",
    "        if i_slide > 0 and j_slide > 0:\n",
    "            scores = np.zeros([i_slide, j_slide])\n",
    "            for i in range(i_slide):\n",
    "                for j in range(j_slide):\n",
    "                    crop = piece_bin[i:i+128,j:j+128]\n",
    "                    scores[i,j] = np.sum(crop)\n",
    "            best_loc = np.where(scores == np.max(scores))\n",
    "            best_loc = np.array([best_loc[0][0], best_loc[1][0]])\n",
    "            piece_crop = piece_original[best_loc[0]:best_loc[0]+128,best_loc[1]:best_loc[1]+128,:]\n",
    "        else:\n",
    "            piece_crop = pad_image(piece_original, [128,128,3])\n",
    "    else:\n",
    "        piece_crop = piece_original\n",
    "        \n",
    "    return piece_crop\n",
    "\n",
    "def isolate_pieces(original, plot=False):\n",
    "    im_prep = comb_transf(original)\n",
    "    im_prep = im_prep.astype(np.uint8)\n",
    "    if plot:\n",
    "        resized = cv2.resize(im_prep, (800,800))\n",
    "        cv2.imshow(f'Thresholded image', resized)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    contours, _ = cv2.findContours(im_prep, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Find the initial centroids\n",
    "    p_pos = np.zeros([len(contours), 2])\n",
    "    for idx, contour in enumerate(contours):\n",
    "        canvas = np.zeros_like(im_prep)\n",
    "        cv2.fillPoly(canvas, [contour], color=(255))\n",
    "\n",
    "        moments = cv2.moments(contour)\n",
    "        if moments['m00'] != 0:\n",
    "            cx = moments['m10'] / moments['m00']\n",
    "            cy = moments['m01'] / moments['m00']\n",
    "        else:\n",
    "            canvas = np.zeros_like(im_prep)\n",
    "            cv2.fillPoly(canvas, [contour], color=(255))\n",
    "            resized = cv2.resize(canvas, (800,800))\n",
    "            cv2.imshow(f'test', resized)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            cx = 0\n",
    "            cy = 0\n",
    "#             contours.remove(contour)\n",
    "            \n",
    "        p_pos[idx,:] = [cx, cy]\n",
    "\n",
    "    # Merge pieces that are very close together using DBSCAN\n",
    "    db = DBSCAN(eps=75, min_samples=1).fit(p_pos)\n",
    "    \n",
    "#     plt.scatter(p_pos[:,0], p_pos[:,1])\n",
    "        \n",
    "    merged_contours = []\n",
    "    stuck_pieces = []\n",
    "    merged_contours_areas = []\n",
    "    for labs in range(np.max(db.labels_)+1):\n",
    "        to_merge = np.where(db.labels_ == labs)[0]\n",
    "        merged_i = contours[to_merge[0]]\n",
    "        for i in range(1,len(to_merge)):\n",
    "            merged_i = np.concatenate((merged_i, contours[to_merge[i]]), axis=0)\n",
    "        merged_contours.append(merged_i)\n",
    "        merged_contours_areas.append(cv2.contourArea(merged_i))\n",
    "        if cv2.contourArea(merged_i) >= piece_dim**2*1.5:\n",
    "            stuck_pieces.append(merged_i)\n",
    "\n",
    "    # Delete too small pieces (Noise) or too large pieces (stuck)\n",
    "    to_delete = np.where(np.array(merged_contours_areas) <= piece_dim**2*0.3)\n",
    "    to_delete = np.append(to_delete, np.where(np.array(merged_contours_areas) >= piece_dim**2*1.5))\n",
    "    merged_contours = np.delete(np.array(merged_contours, dtype=object), to_delete)\n",
    "    merged_contours = list(merged_contours)\n",
    "    \n",
    "    for idx, stuck_piece in enumerate(stuck_pieces):\n",
    "        canvas = np.zeros_like(im_prep)\n",
    "        cv2.fillPoly(canvas, [stuck_piece], color=(255))\n",
    "        \n",
    "        if plot:\n",
    "            resized = cv2.resize(canvas, (800,800))\n",
    "            cv2.imshow(f'stuck_piece {idx+1}', resized)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        # Open the stuck pieces to seperate them\n",
    "        kernel = np.ones((25,25), np.uint8)\n",
    "        canvas = cv2.morphologyEx(canvas, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        # Find the resulting pieces\n",
    "        rebuilt_conts, _ = cv2.findContours(canvas, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        for cont in rebuilt_conts:\n",
    "            canvas = np.zeros_like(im_prep)\n",
    "            cv2.fillPoly(canvas, [cont], color=(255))\n",
    "            merged_contours.append(cont)\n",
    "\n",
    "            # Show result\n",
    "            if plot:\n",
    "                resized = cv2.resize(canvas, (800,800))\n",
    "                cv2.imshow(f'rebuilt_cont', resized)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "    \n",
    "    # Print effect of filtering\n",
    "    #print(f\"Initial number of pieces : {len(contours)}, merged number of pieces : {len(merged_contours)}\")\n",
    "    \n",
    "    segmented_mask = np.zeros_like(im_prep)\n",
    "    cv2.fillPoly(segmented_mask, merged_contours, color=(255))\n",
    "    \n",
    "    # Show the effect of filtering\n",
    "    if plot:\n",
    "        resized = cv2.resize(segmented_mask, (800,800))\n",
    "        cv2.imshow(f'Post-filtering', resized)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    # Crop and rotate each piece\n",
    "    pieces = np.zeros([len(merged_contours), piece_dim, piece_dim, 3], dtype=np.uint8)\n",
    "    for idx, contour in enumerate(merged_contours):\n",
    "        # Define canvases\n",
    "        canvas = np.zeros_like(im_prep)\n",
    "        cv2.fillPoly(canvas, [contour], color=(255))\n",
    "\n",
    "        # Find bounding boxes\n",
    "        coords = cv2.findNonZero(canvas)\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(coords)\n",
    "        # Padd to have a margin of error\n",
    "        x1 = max(0, x1 - max(0, int(np.ceil((piece_dim*1.5 - w1)/2))))\n",
    "        y1 = max(0, y1 - max(0, int(np.ceil((piece_dim*1.5 - h1)/2))))\n",
    "        w1 = max(w1, int(piece_dim*1.5))\n",
    "        h1 = max(h1, int(piece_dim*1.5))\n",
    "\n",
    "        crop_canvas = canvas[y1:y1+h1, x1:x1+w1]\n",
    "\n",
    "        # Rotate by the right angle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        angle = rect[2]\n",
    "        rotated = imutils.rotate(crop_canvas, angle=angle)\n",
    "        \n",
    "        coords = cv2.findNonZero(rotated)\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(coords)\n",
    "        # Padd to have a margin of error\n",
    "        x2 = max(0, x2 - max(0, int(np.ceil((piece_dim - w2)/2))))\n",
    "        y2 = max(0, y2 - max(0, int(np.ceil((piece_dim - h2)/2))))\n",
    "        w2 = max(w2, int(piece_dim))\n",
    "        h2 = max(h2, int(piece_dim))\n",
    "        final = rotated[y2:y2+h2, x2:x2+w2]\n",
    "        \n",
    "        # Apply all operations on the full image\n",
    "        canvas_full = original.copy()\n",
    "        crop_canvas_full = canvas_full[y1:y1+h1, x1:x1+w1]\n",
    "        rotated_full = imutils.rotate(crop_canvas_full, angle=angle)\n",
    "        final_full = rotated_full[y2:y2+h2, x2:x2+w2]\n",
    "        final_full = opt_crop(final, final_full)\n",
    "        \n",
    "        pieces[idx,:,:,:] = final_full.astype(np.uint8)\n",
    "        #pieces.append(final_full)\n",
    "        if plot:\n",
    "            resized = cv2.resize(canvas, (800,800))\n",
    "            cv2.imshow(f'Post-filtering', resized)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            cv2.imshow(f'Post-filtering', pieces[idx,:,:,:])\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    return pieces, segmented_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Description\n",
    "\n",
    "def create_gabor_kernels():\n",
    "    kernels =[]\n",
    "    theta_nb = 4\n",
    "    theta = np.arange(0, np.pi, np.pi/theta_nb)\n",
    "    group_size = 2\n",
    "    lambd = np.array([1,3,9,15,30,45])\n",
    "    sigma = np.array([3,6,9])\n",
    "    #lambd = np.array([1,15,45])\n",
    "    #sigma = np.array([3,9])\n",
    "    ksize=sigma.max()*3*2+1\n",
    "    for s in sigma:\n",
    "        for f in 1/lambd:\n",
    "            #kernel = np.zeros((theta_nb//group_size + 1, 3, ksize, ksize))\n",
    "            kernel = np.zeros((theta_nb//group_size, 3, ksize, ksize))\n",
    "            for i, t in enumerate(theta):\n",
    "                k = np.real(gabor_kernel(frequency=f, theta=t, sigma_x=s, sigma_y=s/3))\n",
    "                i =i%(theta_nb//group_size)\n",
    "                kernel[i,:,:,:] += skimage.transform.resize(k, (ksize,ksize), mode='constant', cval=0)\n",
    "            #k = np.real(gabor_kernel(frequency=f, theta=0, sigma_x=s, sigma_y=s))\n",
    "            #kernel[-1,:,:,:] = skimage.transform.resize(k, (ksize,ksize), mode='constant', cval=0)\n",
    "            kernel = torch.tensor(kernel,dtype=torch.float64)\n",
    "            kernels.append(kernel)\n",
    "    kernels = torch.cat(kernels)\n",
    "    return kernels\n",
    "\n",
    "def compute_features(kernels, images):\n",
    "    k_size= kernels.shape[-1]\n",
    "    p_size = k_size//2\n",
    "    images_padded = F.pad(images,(p_size,p_size,p_size,p_size),mode='reflect')\n",
    "\n",
    "    features = []\n",
    "    for img in images_padded:\n",
    "        img =img.unsqueeze(0)\n",
    "        feature = F.conv2d(img, kernels, padding=0)\n",
    "        features.append(feature)\n",
    "    features = torch.cat(features)\n",
    "    return features\n",
    "\n",
    "def compute_descriptors(features, images, k_best=-1):\n",
    "    mean_descriptor = features.mean(axis=(2,3))\n",
    "    std_descriptor = features.std(axis=(2,3))\n",
    "    mean_color=torch.mean(images, axis=(2,3))\n",
    "    std_color = torch.std(images, axis=(2,3))\n",
    "    descriptors = torch.cat((mean_descriptor,std_descriptor, mean_color, std_color),axis=1)\n",
    "    d_min,_ = torch.min(descriptors, axis=0)\n",
    "    d_max,_ = torch.max(descriptors, axis=0)\n",
    "    descriptors = (descriptors-d_min)/(d_max-d_min)\n",
    "    \n",
    "    if k_best!=-1:\n",
    "        if k_best>descriptors.shape[-1]:\n",
    "            k_best=descriptors.shape[-1]\n",
    "        top_k,_ = torch.topk(torch.std(descriptors,axis=0),k_best)\n",
    "        threshold = top_k[-1]\n",
    "        descriptors = np.delete(descriptors, np.where(torch.std(descriptors,axis=0) < threshold), axis=1)\n",
    "    return descriptors\n",
    "\n",
    "def get_descriptors(tiles):\n",
    "    tiles=torch.tensor(tiles).to(torch.float64).permute(0,3,1,2)\n",
    "    kernels = create_gabor_kernels()\n",
    "    features = compute_features(kernels, tiles)\n",
    "    descriptors_reduced = compute_descriptors(features, tiles, k_best=15)\n",
    "    return descriptors_reduced\n",
    "    \n",
    "    \n",
    "\n",
    "##### Classification\n",
    "\n",
    "def clustering(descriptors, dataset, max_dist=0.1, min_tiles=7, max_outliers=3, show_puzzles=False):\n",
    "    dataset=torch.tensor(dataset).to(torch.float64).permute(0,3,1,2)\n",
    "    restart = True\n",
    "    while restart==True:\n",
    "        outliers = torch.tensor([])\n",
    "        clusters = DBSCAN(eps=max_dist, min_samples=min_tiles).fit(descriptors)\n",
    "        labels_cluster, labels_count = np.unique(clusters.labels_, return_counts=True)    \n",
    "\n",
    "        puzzles = []\n",
    "        clusters_solution = []\n",
    "        for i, label in enumerate(labels_cluster):\n",
    "            indexes = np.where(clusters.labels_ == label)\n",
    "            tiles = dataset[indexes]\n",
    "            if label !=-1:\n",
    "                puzzles.append(tiles)\n",
    "                tiles_np=tiles.permute(0,2,3,1)\n",
    "                clusters_solution.append(torch.Tensor.numpy(tiles_np))\n",
    "            else:\n",
    "                outliers = tiles\n",
    "                outliers_np=outliers.permute(0,2,3,1)\n",
    "                if len(outliers)>max_outliers:\n",
    "                    max_dist+=0.05\n",
    "                    restart = True\n",
    "                else:\n",
    "                    restart = False\n",
    "        if len(outliers)==0:\n",
    "            max_dist-=0.02\n",
    "            restart = True\n",
    "    clusters_solution.append(torch.Tensor.numpy(outliers_np))\n",
    "        \n",
    "    if show_puzzles==True:\n",
    "        for i, puzzle in enumerate(puzzles):\n",
    "            print(f'Puzzle {i+1}')\n",
    "            l = len(puzzle)\n",
    "            w = 16\n",
    "            h = l//w+1 if l%w!=0 else l//w\n",
    "            fig, axes = plt.subplots(h,w,figsize=(2*w,2*h),layout='tight')\n",
    "            for i, ax in enumerate(axes.flatten()):\n",
    "                if i<l:\n",
    "                    tile = puzzle[i].to(torch.uint8).permute(1,2,0)\n",
    "                    ax.imshow(tile, cmap='gray')\n",
    "                ax.axis('off')\n",
    "            plt.show()\n",
    "       \n",
    "        print('Outliers')\n",
    "        if outliers!=None:\n",
    "            l = len(outliers)\n",
    "            w = 16\n",
    "            h = l//w+1 if l%w!=0 else l//w\n",
    "            fig, axes = plt.subplots(h,w,figsize=(2*w,2*h),layout='tight')\n",
    "            for i, ax in enumerate(axes.flatten()):\n",
    "                if i<l:\n",
    "                    tile = outliers[i].to(torch.uint8).permute(1,2,0)\n",
    "                    ax.imshow(tile, cmap='gray')\n",
    "                ax.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    return clusters_solution, puzzles, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleSolver():\n",
    "    def __init__(self, pieces, margin=2):\n",
    "        self.piece_dim = 128\n",
    "        self.pieces = pieces\n",
    "        self.margin = margin\n",
    "        self.already_placed = []\n",
    "        self.to_check = []\n",
    "        self.solution = []\n",
    "        self.canvas = np.zeros([2000,2000,3], dtype=np.uint8)\n",
    "        \n",
    "        # Get borders\n",
    "        self.get_borders()\n",
    "        \n",
    "    def get_borders(self):\n",
    "        n_p = self.pieces.shape[0]\n",
    "        borders = np.zeros([n_p, 4, 4, self.piece_dim, 3]) # [piece, 4 rots, 4 sides, side len, channels]\n",
    "\n",
    "        for idx, p in enumerate(self.pieces):\n",
    "            for i in range(4):\n",
    "                borders[idx, i, 0, :, :] = imutils.rotate(p, angle=90*i)[0+self.margin,:,:] # Top border\n",
    "                borders[idx, i, 1, :, :] = imutils.rotate(p, angle=90*i)[:,piece_dim-1-self.margin,:] # Right border\n",
    "                borders[idx, i, 2, :, :] = imutils.rotate(p, angle=90*i)[piece_dim-1-self.margin,:,:] # Bottom border\n",
    "                borders[idx, i, 3, :, :] = imutils.rotate(p, angle=90*i)[:,0+self.margin,:] # Left border\n",
    "\n",
    "        self.borders = borders\n",
    "\n",
    "    def best_match(self, ref_idx):\n",
    "        interest_side = (ref_idx[2]+2)%4\n",
    "        ref_border = self.borders[ref_idx[0], ref_idx[1], ref_idx[2], :, :]\n",
    "        comp = np.full([self.borders.shape[0], self.borders.shape[1], self.borders.shape[2]], np.inf)\n",
    "        for i in range(self.borders.shape[0]): # Iter through pieces\n",
    "            if i != ref_idx[0] and not(i in self.already_placed):\n",
    "                for j in range(self.borders.shape[1]): # Iter through orientations\n",
    "                    for k in range(self.borders.shape[2]): # Iter through sides\n",
    "                        if k == interest_side:\n",
    "                            comp[i,j,k] = np.sum(np.absolute(ref_border - self.borders[i,j,k,:,:]))\n",
    "\n",
    "        min_pos = np.array(np.unravel_index(np.argmin(comp), comp.shape))\n",
    "        \n",
    "        return min_pos, np.min(comp)\n",
    "    \n",
    "    def try_all(self):\n",
    "        values_arr = np.full([self.borders.shape[0], self.borders.shape[1], self.borders.shape[2]], np.inf)\n",
    "        for i in range(self.borders.shape[0]): # Iter through pieces\n",
    "            for j in range(self.borders.shape[1]): # Iter through orientations\n",
    "                for k in range(self.borders.shape[2]): # Iter through sides\n",
    "                    if [i,j,k] in self.to_check:\n",
    "                        ref_idx = np.array([i,j,k])\n",
    "                        _, value = self.best_match(ref_idx)\n",
    "                        values_arr[i,j,k] = value\n",
    "\n",
    "        return values_arr\n",
    "\n",
    "    def get_sides(self, piece_idx):\n",
    "        sides = []\n",
    "        for i in range(4):\n",
    "            sides.append([piece_idx[0], piece_idx[1], i])\n",
    "        return sides\n",
    "    \n",
    "    def get_loc(self, ref_piece):\n",
    "        for i in range(len(self.solution)):\n",
    "            if self.solution[i][0] == [ref_piece[0], ref_piece[1]]:\n",
    "                ref_loc = self.solution[i][1]\n",
    "                if ref_piece[2] == 0:\n",
    "                    match_loc = [ref_loc[0]-1, ref_loc[1]]\n",
    "                if ref_piece[2] == 1:\n",
    "                    match_loc = [ref_loc[0], ref_loc[1]+1]\n",
    "                if ref_piece[2] == 2:\n",
    "                    match_loc = [ref_loc[0]+1, ref_loc[1]]\n",
    "                if ref_piece[2] == 3:\n",
    "                    match_loc = [ref_loc[0], ref_loc[1]-1]\n",
    "                \n",
    "                break\n",
    "        \n",
    "        return match_loc\n",
    "    \n",
    "    def check_loc(self, match_loc):\n",
    "        valid = True\n",
    "        for i in range(len(self.solution)):\n",
    "            if self.solution[i][1] == [match_loc[0], match_loc[1]]:\n",
    "                valid = False\n",
    "#                 print(f\"Invalid loc = {match_loc}\")\n",
    "        \n",
    "        return valid\n",
    "        \n",
    "    def solve(self):\n",
    "        # Reset solution\n",
    "        self.soltion = []\n",
    "        \n",
    "        # Place first piece\n",
    "        p0_idx = [0,0] # Piece 0 with orientation 0\n",
    "        p0_loc = [0,0] # Location (0,0)\n",
    "        self.solution.append([p0_idx, p0_loc]) \n",
    "        self.already_placed.append(p0_idx[0])\n",
    "        [self.to_check.append(x) for x in self.get_sides(p0_idx)]\n",
    "\n",
    "        while len(self.already_placed) < len(self.pieces):\n",
    "            # Find best loc\n",
    "            values_arr = self.try_all()\n",
    "            ref_piece = np.array(np.unravel_index(np.argmin(values_arr), values_arr.shape))\n",
    "            match_piece, value = self.best_match(ref_piece)\n",
    "\n",
    "            # Find new piece location\n",
    "            match_idx = [match_piece[0], match_piece[1]]\n",
    "            match_loc = self.get_loc(ref_piece)\n",
    "            \n",
    "            # Check validity of new location\n",
    "            valid = self.check_loc(match_loc)\n",
    "            #print(f\"valid = {valid}\")\n",
    "            if valid :\n",
    "                # Append to solution\n",
    "                self.solution.append([match_idx, match_loc])\n",
    "                \n",
    "                # Update to check and already placed list\n",
    "                self.already_placed.append(match_piece[0])\n",
    "                [self.to_check.append(x) for x in self.get_sides(match_piece)]\n",
    "                self.to_check.remove(list(ref_piece))\n",
    "                self.to_check.remove(list(match_piece))\n",
    "            else :\n",
    "                # Edge leads to a taken place, remove from check list\n",
    "                self.to_check.remove(list(ref_piece))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def print_piece(self, piece_idx, position):\n",
    "        origin = np.array([self.canvas.shape[0]/2, self.canvas.shape[1]/2], dtype=int)\n",
    "        origin -= int(self.piece_dim/2)\n",
    "        \n",
    "        self.canvas[origin[0]+position[0]*self.piece_dim:origin[0]+(position[0]+1)*self.piece_dim, \n",
    "                    origin[1]+position[1]*self.piece_dim:origin[1]+(position[1]+1)*self.piece_dim, \n",
    "                    :] = imutils.rotate(self.pieces[piece_idx[0]], angle=90*piece_idx[1])\n",
    "        \n",
    "    def draw_sol(self):\n",
    "        for i in range(len(self.solution)):\n",
    "            self.print_piece(self.solution[i][0], self.solution[i][1])\n",
    "        \n",
    "        # Crop around solution\n",
    "        coords = cv2.findNonZero(cv2.cvtColor(self.canvas, cv2.COLOR_BGR2GRAY))\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        self.canvas = self.canvas[y:y+h, x:x+w]\n",
    "        \n",
    "    def display(self):\n",
    "        plt.imshow(self.canvas)\n",
    "        \n",
    "    def save(self):\n",
    "        pass\n",
    "        \n",
    "def solve_puzzles(clusters):\n",
    "    solved_puzzles = []\n",
    "    for i in range(len(clusters)):\n",
    "        myPuzzle = PuzzleSolver(clusters[i])\n",
    "        myPuzzle.solve()\n",
    "        myPuzzle.draw_sol()\n",
    "        solved_puzzles.append(myPuzzle.canvas)\n",
    "        \n",
    "    return solved_puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(original):\n",
    "    tiles, seg_mask = isolate_pieces(original)\n",
    "    descriptors = get_descriptors(tiles)\n",
    "    clusters, _, _ = clustering(descriptors, tiles, show_puzzles=False)\n",
    "    solved_puzzles = solve_puzzles(clusters)\n",
    "        \n",
    "    solutions = [seg_mask, torch.Tensor.numpy(descriptors), clusters, solved_puzzles]\n",
    "    \n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all(folder = \"test\", path = \"data_project\"):\n",
    "    dir_path = os.path.join(path, folder)\n",
    "    nb_samples = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "    for image_index in range(nb_samples):\n",
    "        original = load_input_image(image_index, folder = folder, path = path)\n",
    "        solutions = process(original)\n",
    "        export_solutions(image_index, solutions, path=path, group_id=\"14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "image_index = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">saving solutions in folder:  data_project\\solutions_group_14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "saving solutions in folder:  data_project\\solutions_group_14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m511\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m511\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m255\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_index = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">saving solutions in folder:  data_project\\solutions_group_14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "saving solutions in folder:  data_project\\solutions_group_14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_index = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">saving solutions in folder:  data_project\\solutions_group_14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "saving solutions in folder:  data_project\\solutions_group_14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">639</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m639\u001b[0m, \u001b[1;36m512\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m384\u001b[0m, \u001b[1;36m640\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">383</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m383\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_index = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">saving solutions in folder:  data_project\\solutions_group_14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "saving solutions in folder:  data_project\\solutions_group_14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m640\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">511</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m511\u001b[0m, \u001b[1;36m384\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m256\u001b[0m, \u001b[1;36m256\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_index = 4\n"
     ]
    }
   ],
   "source": [
    "process_all(folder = \"train2\", path = \"data_project\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
