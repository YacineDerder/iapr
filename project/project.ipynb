{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import skimage.morphology\n",
    "from skimage import measure\n",
    "from skimage import io, filters\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR][iapr]: Project\n",
    "\n",
    "\n",
    "**Group ID:** 14\n",
    "\n",
    "**Author 1 (sciper):** David Rüegg (218512)  \n",
    "**Author 2 (sciper):** Yacine Derder (301994)   \n",
    "**Author 3 (sciper):** Elsa Pariat (301964)   \n",
    "\n",
    "**Release date:** 27.04.2023\n",
    "\n",
    "\n",
    "## Important notes\n",
    "\n",
    "The assignments are designed to teach practical implementation of the topics presented during class as well as preparation for the final project, which is a practical project which ties together the topics of the course. \n",
    "\n",
    "As such, in the lab assignments/final project, unless otherwise specified, you may, if you choose, use external functions from image processing/ML libraries like opencv and sklearn as long as there is sufficient explanation in the lab report. For example, you do not need to implement your own edge detector, etc.\n",
    "\n",
    "**! Before handling back the notebook !** rerun the notebook from scratch `Kernel` > `Restart & Run All`\n",
    "\n",
    "\n",
    "[iapr]: https://github.com/LTS5/iapr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Introduction\n",
    "\n",
    "In this project, you will be working on solving tiling puzzles using image analysis and pattern recognition techniques. Tiling puzzles are a classic type of puzzle game that consists of fitting together pieces of a given shape (in this case squared to form a complete image. The goal of this project is to develop an algorithm that can automatically reconstruct tiling puzzles from a single input image. \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data\n",
    "\n",
    "### Input data\n",
    "To achieve your task, you will be given images that look like this:\n",
    "\n",
    "\n",
    "![train_00.png](data_project/project_description/train_00.png)\n",
    "\n",
    "### Example puzzle content\n",
    "Example of input of solved puzzles. \n",
    "Solution 1\n",
    "<img src=\"data_project/project_description/solution_example.png\" width=\"512\"/>\n",
    "Solution 2\n",
    "<img src=\"data_project/project_description/solution_example2.jpg\" width=\"512\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Image layout\n",
    "\n",
    "- The input for the program will be a single image with a size of __2000x2000 pixels__, containing the pieces of the tiling puzzles randomly placed in it. The puzzles sizes vary from __3x3, 3x4, or 4x4__ size. \n",
    "    -__You are guaranteed to always have the exact number of pieces for each puzzle__ \n",
    "        -For each puzzle you always are expected to find exaclty 9,12,16 pieces\n",
    "        -If you find something else, either you are missing pieces, or added incorrect pieces for the puzzle\n",
    "\n",
    "- The puzzle pieces are square-shaped with dimensions of 128x128 pixels (before rotation). \n",
    "\n",
    "- The input image will contain pieces from __two or three (but never four)__ different tiling puzzles, as well as some __extra pieces (outliers)__ that do not belong to either puzzle.\n",
    "\n",
    "\n",
    "## 2. Tasks (Total 20 points) \n",
    "\n",
    "\n",
    "The project aims to:\n",
    "1) Segment the puzzle pieces from the background (recover the pieces of 128x128 pixels)   \\[ __5 points__ \\] \n",
    "\n",
    "2) Extract features of interest from puzzle pieces images \\[ __5 points__ \\]   \n",
    "\n",
    "3) Cluster puzzle pieces to identify which puzzle they belong, and identify outliers.  \\[ __5 points__ \\]   \n",
    "\n",
    "4) Solve tiling puzzle (find the rotations and translations to correctly allocate the puzzle pieces in a 3x3, 3x4 or 4x4 array.) \\[ __5 points__ \\]   \n",
    "\n",
    "##### The images used for the puzzles have self-repeating patterns or textures, which ensures that all puzzle pieces contain more or less the same features regardless of how they were cut. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. Output solution pieces.\n",
    "\n",
    "For each inpute image, the output solution will include N images with solved puzzles, where N is the number of puzzles in the input image. and M images, that are Each of these images will contain the solved solution to one of the N puzzles in the input. \n",
    "\n",
    "\n",
    "-  Example input:  train_05.png\n",
    "\n",
    "- Example solution:\n",
    "        -solution_05_00.png solution_05_01.png solution_05_02.png \n",
    "        -outlier_05_00.png outlier_05_01.png outlier_05_02.png ...\n",
    "\n",
    "- Example input:  train_07.png\n",
    "- Example solution:\n",
    "        -solution_07_00.png solution_07_01.png \n",
    "        -outlier_07_00.png outlier_07_01.png outlier_07_02.png ...\n",
    "\n",
    "\n",
    "__Watch out!__ output resolution should always be like this:  \n",
    "<table ><tr><th >Puzzle pieces <th><th> pixel dimentions <th> <th> pixel dimentions <th> <tr>\n",
    "<tr><td> 3x3 <td><td> 384x384 <td><td> 3(128)x3(128) <td> <tr>\n",
    "<tr><td> 3x4 <td><td> 384x512 <td><td> 3(128)x4(128)<tr>\n",
    "<tr><td> 4x4 <td><td> 512x512 <td><td> 4(128)x4(128)<tr>\n",
    "<tr><td> 1x1 (outlier)<td><td> 128x128 <td><td> (1)128x(1)128 <td><tr><table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Order of the solutions (and rotations) it's not a problem for the grading__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "the output solution will be a final image of resolution (1283)x(1283), with each piece correctly placed in its corresponding location in the 3x3 array. Similarly, if the puzzle consists of 3x4 or 4x4 pieces, the output solution will be an image of resolution (1283)x(1284) or (1284)x(1284)\n",
    "\n",
    "\n",
    "\n",
    "### 1.3 Data folder Structure\n",
    "\n",
    "You can download the data for the project here: [download data](https://drive.google.com/drive/folders/1k3xTH0ZhpqZb3xcZ6wsOSjLzxBNYabg3?usp=share_link)\n",
    "\n",
    "```\n",
    "data_project\n",
    "│\n",
    "└─── project_description\n",
    "│    │    example_input.png      # example input images\n",
    "│    │    example_textures1.png      # example input images\n",
    "│    │    example_textures2.png      # example input images\n",
    "│    └─── ultimate_test.jpg   # If it works on that image, you would probably end up with a good score\n",
    "│\n",
    "└─── train\n",
    "│    │    train_00.png        # Train image 00\n",
    "│    │    ...\n",
    "│    │    train_16.png        # Train image 16\n",
    "│    └─── train_labels.csv    # Ground truth of the train set\n",
    "|    \n",
    "└────train_solution\n",
    "│    │    solution_00_00.png        # Solution puzzle 1 from Train image 00\n",
    "│    │    solution_00_01.png        # Solution puzzle 2 from Train image 00\n",
    "│    │    solution_00_02.png        # Solution Puzzle 3 from Train image 00\n",
    "│    │    outlier_00_00.png         # outlier     from Train image 00\n",
    "│    │    outlier_00_01.png         # outlier     from Train image 00\n",
    "│    │    outlier_00_03.png         # outlier     from Train image 00\n",
    "│    │    ...\n",
    "│    │    solution_15_00.png        # Solution puzzle 1 from Train image 15\n",
    "│    │    solution_15_01.png        # Solution puzzle 2 from Train image 15\n",
    "│    │    outlier_15_00.png         # outlier     from Train image 15\n",
    "│    └─── outlier_15_01.png         # outlier     from Train image 15\n",
    "│\n",
    "└─── test\n",
    "     │    test_00.png         # Test image 00 (day of the exam only)\n",
    "     │    ...\n",
    "     └─── test_xx.png             # Test image xx (day of the exam only)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "**Before the exam**\n",
    "   - Create a zipped folder named **groupid_xx.zip** that you upload on moodle (xx being your group number).\n",
    "   - Include a **runnable** code (Jupyter Notebook and external files) and your presentation in the zip folder.\n",
    "   \n",
    "**The day of the exam**\n",
    "   - You will be given a **new folder** (test folder) with few images, but **no ground truth** (no solutions).\n",
    "   - We will ask you to run your pipeline in **real time** and to send us your prediction of the task you obtain with the provided function **save_results**. \n",
    "   - On our side, we will compute the performance of your classification algorithm. \n",
    "   - To evaluate your method, we will use the **evaluate_solution** function presented below. To understand how the provided functions work, please read the documentation of the functions in **utils.py**.\n",
    "   - **Please make sure your function returns the proper data format to avoid points penalty on the day of the exam**. \n",
    "---\n",
    "\n",
    "\n",
    "## 4. Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load images\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_input_image(image_index ,  folder =\"train\" , path = \"data_project\"):\n",
    "    \n",
    "    filename = \"train_{}.png\".format(str(image_index).zfill(2))\n",
    "    path_solution = os.path.join(path,folder , filename )\n",
    "    \n",
    "    im= Image.open(os.path.join(path,folder,filename)).convert('RGB')\n",
    "    im = np.array(im)\n",
    "    return im\n",
    "\n",
    "def save_solution_puzzles(image_index , solved_puzzles, outliers  , folder =\"train\" , path = \"data_project\"  ,group_id = 0):\n",
    "    \n",
    "    path_solution = os.path.join(path,folder + \"_solution_{}\".format(str(group_id).zfill(2)))\n",
    "    if not  os.path.isdir(path_solution):\n",
    "        os.mkdir(path_solution)\n",
    "\n",
    "    print(path_solution)\n",
    "    for i, puzzle in enumerate(solved_puzzles):\n",
    "        filename =os.path.join(path_solution, \"solution_{}_{}.png\".format(str(image_index).zfill(2), str(i).zfill(2)))\n",
    "        Image.fromarray(puzzle).save(filename)\n",
    "\n",
    "    for i , outlier in enumerate(outliers):\n",
    "        filename =os.path.join(path_solution, \"outlier_{}_{}.png\".format(str(image_index).zfill(2), str(i).zfill(2)))\n",
    "        Image.fromarray(outlier).save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_and_export_puzzles_image(image_index , folder = \"train\" , path = \"data_project\"  , group_id = \"00\"):\n",
    "    \"\"\"\n",
    "    Wrapper funciton to load image and save solution\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    image:\n",
    "        index number of the dataset\n",
    "\n",
    "    Returns\n",
    "    \"\"\"\n",
    "\n",
    "      # open the image\n",
    "    image_loaded = load_input_image(image_index , folder = folder , path = path)\n",
    "    #print(image_loaded)\n",
    "    \n",
    "   \n",
    "    ## call functions to solve image_loaded\n",
    "    solved_puzzles = [ (np.random.rand(512,512,3)*255).astype(np.uint8)  for i in range(2) ]\n",
    "    outlier_images = [ (np.random.rand(128,128,3)*255).astype(np.uint8) for i in range(3)]\n",
    "    \n",
    "    save_solution_puzzles (image_index , solved_puzzles , outlier_images , folder = folder ,group_id =group_id)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    return image_loaded , solved_puzzles , outlier_images\n",
    "\n",
    "im, sol , out = solve_and_export_puzzles_image(6 , group_id = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 14\n",
    "# Evaluate all images\n",
    "games_id = [6,10]  # to evaluate  three images\n",
    "\n",
    "for i in games_id :\n",
    "    \n",
    "    print(\"solving \" , i)\n",
    "    # Saving results\n",
    "    solve_and_export_puzzles_image(6 , group_id = group_id)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n",
    "\n",
    "The evaluation metrics will be liberated in the following days. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gabor filters\n",
    "\n",
    "$$ gb(x,y) = \\exp \\left( -\\frac{1}{2} \\left( \\frac{x_{\\theta}^2}{\\sigma^2} + \\frac{y_{\\theta}^2}{(\\Gamma\\sigma)^2} \\right) \\right) \\cos \\left( \\frac{2 \\pi}{\\lambda} x_{\\theta} + \\psi \\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gabor\n",
    "from skimage import data, io, color\n",
    "\n",
    "image = color.rgb2gray(data.astronaut())\n",
    "\n",
    "# Define the parameters for the Gabor filter\n",
    "frequency = 0.6\n",
    "theta = np.pi / 4\n",
    "bandwidth = 1\n",
    "sigma_x = 5\n",
    "sigma_y = 5\n",
    "\n",
    "# Apply the Gabor filter to the image\n",
    "real, imag = gabor(image, frequency=frequency, theta=theta,\n",
    "                   bandwidth=bandwidth, sigma_x=sigma_x, sigma_y=sigma_y)\n",
    "\n",
    "# Plot the original image and the filtered images\n",
    "fig, (ax_orig, ax_real, ax_imag) = plt.subplots(ncols=3, figsize=(8, 4),\n",
    "                                                 sharex=True, sharey=True)\n",
    "ax_orig.imshow(image, cmap='gray')\n",
    "ax_orig.set_title('Original')\n",
    "ax_orig.axis('off')\n",
    "\n",
    "ax_real.imshow(real, cmap='gray')\n",
    "ax_real.set_title('Real')\n",
    "ax_real.axis('off')\n",
    "\n",
    "ax_imag.imshow(imag, cmap='gray')\n",
    "ax_imag.set_title('Imaginary')\n",
    "ax_imag.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all input images\n",
    "\n",
    "# Get number of train inputs\n",
    "dir_path = r'data_project\\train'\n",
    "nb_train_samples = len([entry for entry in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, entry))])\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, figsize = (15,10))\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        ax[i,j].imshow(load_input_image(5*i + j))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img, th_val = 160, trans=\"rgb\", c_k_size=25):\n",
    "    \n",
    "    if trans == \"rgb\":\n",
    "        mean_rgb = np.mean(img, axis=(0,1))\n",
    "        pix_dist = np.linalg.norm(img - mean_rgb, axis = 2)\n",
    "    elif trans == \"hsv\":\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        mean_hsv = np.mean(hsv, axis=(0,1))\n",
    "        pix_dist = np.linalg.norm(hsv - mean_hsv, axis = 2)\n",
    "    else:\n",
    "        raise Exception(\"Invalid Transformation\")\n",
    "    \n",
    "    # Threshold\n",
    "    im_prep = np.zeros_like(pix_dist)\n",
    "    im_prep[pix_dist > th_val] = 255\n",
    "    \n",
    "    # Remove small holes and objects\n",
    "    im_prep = skimage.morphology.remove_small_holes(im_prep.astype(bool), area_threshold=10000).astype(float)*255\n",
    "    im_prep = skimage.morphology.remove_small_objects(im_prep.astype(bool), min_size=100).astype(float)*255\n",
    "    \n",
    "    # Close then open\n",
    "    kernel = np.ones((c_k_size,c_k_size), np.uint8)\n",
    "    im_prep = cv2.morphologyEx(im_prep, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return im_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_alt(img, c_k_size=25):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_all = np.concatenate((img, hsv), axis=2)\n",
    "    mean_all = np.mean(img_all, axis=(0,1))\n",
    "    pix_dist = np.linalg.norm(img_all - mean_all, axis = 2)\n",
    "    \n",
    "    # Threshold\n",
    "    im_prep = np.zeros_like(pix_dist)\n",
    "    th_val = filters.threshold_otsu(pix_dist)\n",
    "    im_prep[pix_dist > th_val] = 255\n",
    "    \n",
    "    # Remove small holes and objects\n",
    "    im_prep = skimage.morphology.remove_small_holes(im_prep.astype(bool), area_threshold=10000).astype(float)*255\n",
    "    im_prep = skimage.morphology.remove_small_objects(im_prep.astype(bool), min_size=100).astype(float)*255\n",
    "    \n",
    "    # Close then open\n",
    "    kernel = np.ones((c_k_size,c_k_size), np.uint8)\n",
    "    im_prep = cv2.morphologyEx(im_prep, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return im_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_n_pieces = 30\n",
    "piece_dim = 128\n",
    "\n",
    "def sel_transf(img, margin = 0.1):\n",
    "    exp_n_pix = exp_n_pieces*piece_dim**2*(1 - margin)\n",
    "    transforms = ['rgb', 'hsv', 'all']\n",
    "    \n",
    "    im_prep = np.zeros([img.shape[0], img.shape[1], 3])\n",
    "    im_prep[:,:,0] = preprocess(img, trans=transforms[0])\n",
    "    im_prep[:,:,1] = preprocess(img, trans=transforms[1])\n",
    "    im_prep[:,:,2] = preprocess_alt(img)\n",
    "    \n",
    "    loss = np.array([np.absolute(np.sum(im_prep[:,:,i].astype(bool)) - exp_n_pix) for i in range(im_prep.shape[2])])\n",
    "    \n",
    "    sel_prep = np.argmin(loss)\n",
    "    \n",
    "    return im_prep[:,:,sel_prep], transforms[sel_prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "im_prep, sel_trans = sel_transf(load_input_image(14))\n",
    "\n",
    "print(f\"Chosen preprocessing : {sel_trans}\")\n",
    "resized = cv2.resize(im_prep, (800,800))\n",
    "cv2.imshow('Preprocessed Image', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for all samples\n",
    "for i in range(nb_train_samples):\n",
    "    im_prep, sel_trans = sel_transf(load_input_image(i), margin = 0.1)\n",
    "    \n",
    "    resized = cv2.resize(im_prep, (800,800))\n",
    "    cv2.imshow(f'Image {i+1}, RGB', resized)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Chosen preprocessing : {sel_trans} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def isolate_pieces(original):\n",
    "    pieces = []\n",
    "    im_prep, sel_trans = sel_transf(original, margin = 0.1)\n",
    "    im_prep = im_prep.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(im_prep, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Find the initial centroids\n",
    "    p_pos = np.zeros([len(contours), 2])\n",
    "    for idx, contour in enumerate(contours):\n",
    "        canvas = np.zeros_like(im_prep)\n",
    "        cv2.fillPoly(canvas, [contour], color=(255))\n",
    "\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / moments['m00']\n",
    "        cy = moments['m01'] / moments['m00']\n",
    "\n",
    "        p_pos[idx,:] = [cx, cy]\n",
    "\n",
    "    # Merge pieces that are very close together using DBSCAN\n",
    "    db = DBSCAN(eps=75, min_samples=1).fit(p_pos)\n",
    "\n",
    "    merged_contours = []\n",
    "    merged_contours_areas = []\n",
    "    for labs in range(np.max(db.labels_)+1):\n",
    "        to_merge = np.where(db.labels_ == labs)[0]\n",
    "        merged_i = contours[to_merge[0]]\n",
    "        for i in range(1,len(to_merge)):\n",
    "            merged_i = np.concatenate((merged_i, contours[to_merge[i]]), axis=0)\n",
    "        merged_contours.append(merged_i)\n",
    "        merged_contours_areas.append(cv2.contourArea(merged_i))\n",
    "    \n",
    "    # Delete too small pieces (Noise)\n",
    "    merged_contours = np.delete(merged_contours, np.array(merged_contours_areas) <= piece_dim**2/3)\n",
    "    \n",
    "    # Print effect of filtering\n",
    "    print(f\"Initial number of pieces : {len(contours)}, merged number of pieces : {len(merged_contours)}\")\n",
    "    \n",
    "    # Crop and rotate each piece\n",
    "    p_pos = np.zeros([len(contours), 2])\n",
    "    for idx, contour in enumerate(merged_contours):\n",
    "        # Define canvases\n",
    "        canvas = np.zeros_like(im_prep)\n",
    "        cv2.fillPoly(canvas, [contour], color=(255))\n",
    "        canvas_real = cv2.bitwise_and(original, original, mask=canvas)\n",
    "\n",
    "        # Find bounding boxes\n",
    "        coords = cv2.findNonZero(canvas)\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        crop_canvas = canvas[y:y+h, x:x+w]\n",
    "        crop_canvas_real = canvas_real[y:y+h, x:x+w]\n",
    "\n",
    "        # Rotate by the right angle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        angle = rect[2]\n",
    "        rotated = imutils.rotate(crop_canvas, angle=angle)\n",
    "        rotated_real = imutils.rotate(crop_canvas_real, angle=angle)\n",
    "        coords = cv2.findNonZero(rotated)\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        final_real = rotated_real[y:y+h, x:x+w]\n",
    "\n",
    "        pieces.append(final_real)\n",
    "\n",
    "    return pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "original = load_input_image(14)\n",
    "resized = cv2.resize(original, (800,800))\n",
    "cv2.imshow(f'Original image, RGB', resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pieces = isolate_pieces(original)\n",
    "\n",
    "for i in range(len(pieces)):\n",
    "    cv2.imshow(f'Piece {i+1}, RGB', pieces[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of found pieces : {len(pieces)}\")\n",
    "for piece in pieces:\n",
    "    print(piece.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
